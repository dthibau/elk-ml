input {
    
    file {
        path => "/home/dthibau/Formations/ELK-ML/github/TPs/3_LogstashPipeline/data/plbsi/*.log*"
        start_position => beginning
        codec => multiline {
            pattern => "^\s|^Caused by"
            what => "previous"
        }
    }
}


filter {
  grok {
    match => {
      "message" => [
        # Expression pour parser les logs classiques Spring Boot
        "%{TIMESTAMP_ISO8601:timestamp} +%{LOGLEVEL:log.level} +%{NUMBER:process.id} --- \[%{DATA:thread}\] %{JAVACLASS:logger} +: %{GREEDYDATA:message}"
      ]
    }
    overwrite => ["message"]
  }

  # Ajout de champs personnalisÃ©s (facultatif)
  mutate {
    add_field => {
      "application" => "my-spring-boot-app"
      "environment" => "production"
    }
  }

  # Conversion du timestamp en champ @timestamp standard pour Elasticsearch
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  # Ajout de tags pour les erreurs (facultatif)
  if [log][level] == "ERROR" {
    mutate {
      add_tag => ["error"]
    }
  }

  # Normalisation du niveau de log en minuscule (pour Elastic Common Schema)
  mutate {
    lowercase => ["[log][level]"]
  }
}
output {
   elasticsearch {
        hosts => [ "http://localhost:9200" ]
        data_stream => "true"
        data_stream_dataset => "springboot-app"
        data_stream_namespace => "springboot"
        data_stream_type => "logs"
    }
    stdout { codec => rubydebug }
}

